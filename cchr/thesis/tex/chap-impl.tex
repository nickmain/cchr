\chapter{Ontwerp en implementatie} \label{chap:impl}

In dit hoofdstuk wordt ingegaan op het ontwerp en de implementatie van het CCHR systeem.

\section{Algemeen} \label{sec:impl}

Zoals reeds aangehaald bestaat de implementatie van een CHR systeem normaal uit twee delen: de {\em compiler} en de {\em runtime}. De compiler zorgt voor een vertaling van de CHR-syntax naar code die uitvoerbaar is op het hostplatform en de runtime bevat alles wat noodzakelijk is om de vertaalde code te kunnen uitvoeren (algemene routines, onderhouden van de constraint store, \ldots).

De compiler is zelf in C geschreven en vertaalt CCHR code in enkele stappen tot normale C code, die dan verder door een standaard C compiler vertaald kan worden tot uitvoerbare code: machinetaal voor een specifiek platform. Bij C is het gebruikelijk dat er een volledige compilatie tot machinetaal gebeurt, in plaats van slechts een omzetting tot bytecode zoals in Java. Hierdoor duurt compileren langer en is de uitvoer van de C compiler slechts op \'e\'en platform bruikbaar. Het voordeel is echter dat veel specifiekere machine-optimalisaties mogelijk zijn, waar ook CCHR voordeel uit haalt.

\section{De Compiler} \label{sec:compiler}

\Quote{If the programmer can simulate a construct faster then the compiler can implement the construct itself, then the compiler writer has blown it badly.}{Guy L. Steele Jr., Tartan Laboratories}

De compiler is het belangrijkste deel van het CCHR systeem. Het algemene concept is sterk gebaseerd op JCHR: de CHR broncode wordt naar de hosttaal zelf vertaald, die dan door de bestaande compilers voor die taal verder gecompileerd kan worden tot een echt uitvoerbaar programma. De compiler zelf begint met een parser en lexer om de taalstructuur van de CHR broncode te achterhalen, gevolgd door een omzetting naar een tussenvorm waarop enkele analyses gebeuren en eindigt met een {\em template}-gebaseerde vertaling naar de uiteindelijke hosttaal. De precieze implementatie verschilt wel: \begin{itemize}
  \item De CCHR compiler vertaalt naar C en niet naar Java.
  \item De CCHR compiler is zelf ook in C geschreven. De JCHR compiler was zelf in Java gemaakt.
  \item De gebruikte lexer en parser zijn gegenereerd met {\em Flex} en {\em Bison}, in plaats van {\em ANTLR}.
  \item In plaats van een extern pakket voor de templates te gebruiken, worden standaard C macro's gebruikt.
 \end{itemize}
 
De grote fases zijn min of meer gescheiden van elkaar in de code. Ze zijn elk gedefinieerd in 1 of meerdere aparte bronbestanden en de datastructuren die gebruikt worden voor de communicatie tussen de verschillende modules zijn op zich weer apart gedefinieerd. Zo zal de parser een {\em Abstract Syntax Tree} (AST) als resultaat geven, die enkel door de vertaal/analyse-module gebruikt wordt voor een omzetting naar een tussenvorm, waarop enkele statische analyses uitgevoerd worden. Deze AST kan dan eenvoudig door de codegeneratie tot C macro's te vertaald worden.

\subsection{Algemeen} \label{sec:comp-werking}

De algemene werking van de CCHR compiler is als volgt: \begin{itemize}
  \item Alle op de commandolijn opgegeven bestanden worden doorlopen en letterlijk gekopi\"eerd naar de uitvoer (C).
  \item Als in een van de bestanden een \code{cchr}-blok gevonden wordt: \begin{itemize}
    \item De {\em parser} wordt aangeroepen met dat \code{cchr}-blok als invoer.
    \item De {\em parser} roept zelf de {\em lexer} aan om syntactische elementen te herkennen.
    \item De {\em parser} bouwt een {\em abstract syntax tree} (AST).
    \item De AST wordt geanalyseerd en een tussenvorm wordt opgebouwd.
    \item Op de tussenvorm worden optimalisaties doorgevoerd.
    \item Uiteindelijk wordt de tussenvorm omgezet naar een sequentie van C macro's.
    \item Deze C macro's worden in het uitvoerbestand op de plaats gezet waar het \code{cchr}-blok stond.
  \end{itemize}
\end{itemize}

\subsection{De lexer} \label{sec:lexer}

De lexer is geschreven met behulp van Flex (zie \cite{flex}). Op de website van Flex staat te lezen: \begin{quote}
  Flex is a fast lexical analyser generator. It is a tool for generating programs that perform pattern-matching on text.
\end{quote}

Op basis van een bestand met definities van patronen, in de vorm van {\em regular expressions}, kan Flex een C bronbestand genereren dat heel snel een stuk input kan splitsen in de opgegeven patronen. 

De op deze wijze bekomen {\em lexer} vormt de eerste fase van het compilatieproces. Ze herkent de opeenvolgende sleutelwoorden, operatoren en symbolen (kortweg {\em tokens}) van de brontaal en geeft ze door aan de {\em parser}.

\subsection{De parser} \label{sec:parser}

De parser is geschreven met behulp van Bison (zie \cite{bison}). Op de website van Bison staat te lezen: \begin{quote}
  Bison is a general-purpose parser generator that converts an annotated context-free grammar into an LALR(1) or GLR parser for that grammar.
\end{quote}

Er kan opgemerkt worden dat de werkwijze van Bison sterk lijkt op de CCHR compiler zelf. Er wordt ook uitgegaan van een andere taal die in C ingebed kan worden en met behulp van een template-gebaseerde methode wordt pure C code gegenereerd.

Hiervoor is de grammaticale structuur van CCHR beschreven als een Bison {\em Context-Free Grammar}, met semantische acties erbij die een AST genereren. Er moet wel opgemerkt worden dat hoewel CCHR toelaat arbitraire C code op te nemen, de CCHR grammatica geen volledige C grammatica bevat. Slechts een deel van de taalstructuren worden geparset. Functie-aanroepen en variabelenamen worden herkend, maar operatoren worden onverwerkt doorgegeven. Dat wil bijvoorbeeld zeggen dat \code{1+2*(3-4)} gewoonweg als \code{1 + 2 * ( 3 - 4 )} beschouwd wordt en niet als \code{+(1,*(2,-(3,4)))}. Het letterlijk doorgeven van C expressies volstaat, aangezien alles toch nog door de C compiler zelf moet.

Voor de {\em tokens} die de grammatica als basisblokken gebruikt, wordt beroep gedaan op de {\em lexer}.

Het resultaat hiervan is dus een AST, die echter helemaal niet geschikt is om er converties en analyses op uit te voeren. Alle variabelen, constraints, \ldots zijn nog steeds beschreven als een hoop tekenreeksen. In de volgende stap wordt dit omgezet naar een handiger formaat. 

\subsection{De tussenvorm} \label{sec:tussenvorm}

Na deze stap wordt de AST omgezet naar een nieuwe datastructuur, waarbij constraints, variabelen, regels, \ldots als specifieke structuren in plaats van als tekenreeksen beschreven worden. 

De reden om de parser niet onmiddellijk via semantische acties deze tussenvorm te laten genereren is meer vrijheid in de taal te kunnen toelaten. Zo is het nu bijvoorbeeld mogelijk om een constraint pas te defini\"eren nadat die in een CHR regel gebruikt is, of een CHR variabele pas als argument in een head gebruiken nadat deze variabele al in een expressie is voorgekomen.

Tijdens de omzetting van AST naar deze tussenvorm worden volgende transformaties doorgevoerd: \begin{itemize}
\item Alle verwijzingen naar constraints, variabelen, opties, \ldots worden herkend.
\item Alle regels worden omgezet naar HNF (Head Normal Form), waarbij alle expressies als parameters van constraints in de head die geen unieke variabelen zijn door een nieuwe variabele plus een extra guard vervangen worden.
\item CHR macro's worden vervangen door hun definitie (zie sectie~\ref{sec:rules}).
\item Constraint occurrences worden bepaald (in welke regels en op welke plaats daarin elke constraint voorkomt).
\item Variabele occurrences worden bepaald (in welke constraint occurrence en op welke plaats daarin elke variabele voorkomt).
\item Afhankelijkheden tussen variabelen en statements worden bepaald.
\item Met deze afhankelijkheden wordt voor elke constraint occurrence een goede ``join ordering'' bepaald (zie sectie~\ref{sec:joinorder}).
\end{itemize}

\subsection{Codegeneratie} \label{sec:codegen}

In de laatste fase van het vertalingsproces wordt de tussenvorm omgezet naar C code. Bij JCHR wordt van de template engine FreeMarker gebruik gemaakt. Het voordeel van templates te gebruiken is duidelijk: de code die door de compiler zelf gegenereerd moet worden is algemener en beschrijft het proces op hoger niveau. Implementatie details zoals datastructuren kunnen dan onafhankelijk van de compiler uitgewerkt worden, wat het geheel flexibeler maakt en de kans op fouten beperkt.

In C bestaat echter reeds een gestandaardiseerd macrosysteem. Er is dan ook voor gekozen om deze C macro's te gebruiken in plaats van een aparte template engine. Het programma dat de macro-vertalingen doet, de C voorverwerker (of {\em preprocessor}), is standaard deel van het compilatieschema van C, waardoor het overbodig is om in de CCHR compiler deze vertaling te doen.

Het resultaat is dat het volledige template-vertaalproces verschoven wordt van de CCHR compiler naar het C compilatieschema en de uitvoer van de CCHR compiler wordt een sequentie van C macro's in plaats van echte C code.

Het voordeel hiervan is dat de uitvoer van de CCHR compiler heel leesbaar blijft en onafhankelijk blijft van enkele details. Zo is het mogelijk om een debugversie van het CCHR programma te cre\"eren zonder de CCHR compiler opnieuw te moeten uitvoeren (zie sectie~\ref{sec:debug}), enkel het resultaat ervan hercompileren met de C compiler volstaat. Het belangrijkste nadeel is de moeilijkheden die het gebruik van macro's veroorzaakt bij het debuggen. Zo is het niet mogelijk de code die door de voorverwerker geproduceerd wordt een verwijzing te laten bevatten naar de oorspronkelijke lijnnummers in het CCHR bronbestand. Daardoor zullen C syntaxfouten in de body's van regels geen zinvolle waarschuwingen of foutmeldingen geven.

De gegenereerde code wordt in detail uitgewerkt in sectie~\ref{sec:gencode}.

\subsection{Uitvoer module} \label{sec:uitvoer}

Uiteindelijk roept de codegenerator een uitvoer module aan, die verantwoordelijk is voor het mooi ge\"indenteerd wegschrijven van de gegenereerde code naar het uitvoerbestand en ondertussen informatie bij te houden over het aantal geschreven regels. Dit is nodig omdat er lijnen van de vorm: \begin{Verbatim}
  #line "source.cchr" 16
  ...
  #line "source.c" 214
\end{Verbatim}
in de uitvoer gezet worden, die de C compiler hints geven over waar de code in het bestand vandaan kwam, om zinvollere waarschuwingen te kunnen geven. Het nut hiervan is eerder beperkt, aangezien het grootste deel van de code macrodefinities zijn, waarbij deze techniek niet opgaat.

\section{Gegenereerde code} \label{sec:gencode}

Zoals gezegd bestaat de gegenereerde code uit C macro's. In dit stuk wordt ingegaan op de structuur van die gegenereerde code. Eerst wordt een inleiding gegeven op de C voorverwerker en dan wordt een voorbeeld uitgewerkt, om te eindigen bij de effectieve gegenereerde code die in de appendix te vinden is.

\subsection{De C voorverwerker} \label{sec:preproc}

Eerst een korte inleiding over de C voorverwerker.

Het is een component van het standaard C compilatieproces (voorverwerker, compiler, assembler, linker) en wordt vooral gebruikt om platformafhankelijke definites in te voegen in C programma's. Zo bijvoorbeeld kan met het voorverwerker directief ({\em directive}) \begin{Verbatim}
  #include <stdio.h>
\end{Verbatim}
het {\em headerbestand} \code{stdio.h} ingeladen worden. Volgens de standaard zal dit bestand definities opnemen voor een aantal datatypes en functies nodig voor invoer- en uitvoerroutines. 

Alle ``instructies'' die deze voorverwerker kent heten directieven en moeten op een aparte lijn in het bronbestand staan, te beginnen met een hekje (\code{\#}). De belangrijkste directieven die gebruikt worden in CCHR zijn \code{\#include} en \code{\#define}. \code{\#include} dient om de inhoud van een ander bestand in te voegen, alsof de inhoud van dat bestand op de plaats van de \code{\#include} stond. \code{\#define} dient om een macro te defini\"eren.

Macro's zijn {\em tokens} die gedefinieerd worden als te substitueren door een reeks andere tokens. De eenvoudigste vorm, ook objectvorm genaamd, is: \begin{Verbatim}
  #define FOO bar(1);
\end{Verbatim}
wat aangeeft dat vanaf hier in de code ``\code{FOO}'' vervangen zal worden door ``\code{bar(1);}''. Macro's kunnen echter ook parameters aannemen, de functionele vorm: \begin{Verbatim}
  #define FOO(par) bar(par,par+1);
\end{Verbatim}
waarbij bij voorbeeld de code ``\code{FOO(7)}'' vervangen zal worden door ``\code{bar(7,7+1);}''. Zulke macro's hebben ook ondersteuning voor {\em variable arguments}: \begin{Verbatim}
  #define FOO(par,...) bar(par,__VA_ARGS__)
\end{Verbatim}
Hier zal ``\code{\_\_VA\_ARGS\_\_}'' de plaats innemen van alle argumenten die na \code{par} komen bij de vermelding van \code{FOO}. Zo zal bijvoorbeeld ``\code{FOO(sys,1,2)}'' vervangen worden door ``\code{bar(sys,1,2)}''. De laatste mogelijkheid die gebruikt wordt is {\em token pasting}: \begin{Verbatim}
  #define FOO_1(arg) run(arg)
  #define FOO_2(arg) test(arg)
  #define BAR(par,sys) FOO_##par(sys)
\end{Verbatim}
De \code{\#\#} zorgt hier dat 2 tokens aan elkaar geplakt worden en onderwerpt het resultaat terug aan macro-expansie. Zo zal in bovenstaand voorbeeld ``\code{BAR(1,2)}'' vervangen worden door ``\code{run(2)}'', maar ``\code{BAR(2,1)}'' door ``\code{test(1)}''.

In de komende tekst zal vaak verwezen worden naar macro's, sommigen daarvan staan in het macro-definitie bestand, anderen worden door de compiler gegenereerd. Gegenereerde macro's zullen daarom ook steeds ``gegenereerde macro's'' genoemd worden, om verwarring te vermijden.

\subsection{Algemeen} \label{sec:gencode-alg}

Met het oog de gegenereerde macrocode niet te overladen met informatie die over heel het programma hetzelfde is, zoals de lijst van alle CHR-constraints, is ervoor gekozen om zoveel mogelijk \'e\'enmalig op te slagen. Dit vraagt een woordje uitleg.

Veronderstel dat het CCHR blok uit codefragment~\ref{code:fib-cchr} vertaald moet worden.
\begin{exCode}
\begin{Verbatim}[frame=single]
cchr {
  constraint fib(int,long long),init(int);

  begin @ init(_) ==> fib(0,1LL), fib(1,1LL);
  calc @  init(Max), fib(N2,M2) \ fib(N1,M1) <=>
    alt(N2==N1+1,N2-1==N1), N2<Max |
    fib(N2+1, M1+M2);
}
\end{Verbatim}
\caption{Fibonacci-getallen in CCHR}
\label{code:fib-cchr}
\end{exCode}
De volledige compiler-uitvoer kan gevonden worden in sectie~\ref{sec:out-fib}.

De eerste belangrijke lijn die gegenereerd wordt is deze: 
\begin{Verbatim}
  #define CONSLIST(CB) CB##_D(fib_2) CB##_S CB##_D(init_1)
\end{Verbatim}
Deze lijn defini\"eert welke CHR constraints allemaal bestaan. Ze is heel flexibel in gebruik: de aanroeper moet zelf twee macro's of functies voorzien, \'e\'en voor het defini\"eren van een constraint en \'e\'en voor wat er tussen de expansies van twee opeenvolgende constraints moet komen. Zo is het mogelijk om code te laten genereren voor elke constraint, gescheiden met komma's, mits: \begin{Verbatim}
  #define CB_D(con) CODE_VOOR_CONSTRAINT(con)
  #define CB_S ,
  CONSLIST(CB)
\end{Verbatim}

Deze techniek wordt echter voor meer gebruikt dan enkel het aanduiden van de bestaande CHR constraints. Er worden zulke indexmacro's gedefinieerd voor: \begin{itemize}
\item Welke CHR constraints bestaan (\code{CONSLIST}).
\item De occurrences van elke constraint (\code{RULELIST\_\argu{constraint}\_\argu{ariteit}}).
\item Aantal kept en removed constraints in elke CHR regel (\code{RULE\_KEPT\_\argu{regel}}).
\item Wat en waarin in propagation geschiedenis bij te houden (\code{PROPHIST\_\argu{regel}} en \code{PROPHIST\_HOOK\_\argu{regel}}).
\item Welke indexen nodig zijn en waarover (\code{HASHLIST\_\argu{constraint}\_\argu{ariteit}} en \\ \code{HASHDEF\_\argu{constraint}\_\argu{ariteit}\_\argu{indexnaam}}).
\end{itemize}
Verder worden er nog gelijkaardige, maar eenvoudigere constructies gegenereerd voor constructor, destructor, add en kill routines per CHR constraint.

Dan volgt voor elke constraint occurrence nog een macro die op hoog niveau het uitvoeringsalgoritme beschrijft. Hier gaan we in sectie~\ref{gencode-conocc} op in.

Als afsluiter van de gegenereerde code staat een ``\code{CSM\_START}'', deze macro is gedefinieerd in het algemene macro-definitiebestand (zie runtime) en zal gebruikmakende van alle eerder gegenereerde macrodefinities expanderen tot de uiteindelijke C code. Daaruit volgt dat alle echte CCHR-code schijnbaar op de lijn van deze \code{CSM\_START} komt te staan.

\subsection{Constraint occurrences} \label{gencode-conocc}

Voor elke constraint occurrence wordt een stuk code gegenereerd in de vorm van een aparte macrodefinitie. Eerst wordt hier de basisopbouw gegeven en vanaf sectie~\ref{sec:optim} worden optimalisaties uitgewerkt.

De naam van de gegenereerde macro voor een constraint occurrence moet van de vorm \\ ``\code{CODE\_\argu{occurrence-naam}}'' zijn en mag geen parameters hebben. De benaming voor de occurrence moet gewoon overal dezelfde zijn in de gegenereerde code. In praktijk gebruikt de compiler benamingen als  ``\code{\argu{constraint}\_\argu{ariteit}\_\argu{regel}\_\argu{positie}}''. Positie is hierbij de letter \code{K} voor kept constraints of de letter \code{R} voor removed constraints, gevolgd door een getal dat aanduidt de hoeveelste occurrence van dat type (removed of kept) het is binnen de gegeven regel, te beginnen bij \'e\'en.

Bij de inhoud van de macro's komt het voordeel van een templategebaseerde codegeneratie tot uiting: het algoritme wordt niet als C code gegenereerd, maar als een sequentie van macro's. De verzameling van toegelaten macro's is CSM gedoopt (Constraint Solver Macros) en een volledige lijst beschikbare macro's kan gevonden worden in appendix~\ref{chap:csm}. Het kan nuttig zijn de lijst erbij te nemen bij de komende uitleg, aangezien de precieze betekenis van de CSM macro's hier niet meer uitgelegd wordt.

Als eerste versie wordt vertrokken van een imperatieve versie van de basisuitvoering, zoals beschreven in \cite{tomsphdthesis} en aangehaald in sectie~\ref{sec:schema}:
\begin{enumerate}
  \item Eerst wordt ervoor gezorgd dat de actieve constraint bestaat (\code{CSM\_MAKE}) en toegevoegd is aan de constraint store (\code{CSM\_NEEDSELF}).
  \item Er wordt ge\"itereerd over alle partnerconstraints, zijnde de constraint occurrences in de huidige regel behalve de actieve, met \code{CSM\_LOOP}.
  \item Er wordt gecontroleerd of er geen dubbels zijn in de verschillende partnerconstraints (met \code{CSM\_DIFF} en \code{CSM\_DIFFSELF} binnen een \code{CSM\_IF}).
  \item Er wordt controleerd of de gevonden combinatie nog niet reeds geprobeerd is (met \code{CSM\_CHECKHIST}).
  \item Alle lokale variabelen worden gedefinieerd, met \code{CSM\_DECLOCAL} en \code{CSM\_DEFLOCAL}.
  \item Er wordt gecontroleerd of aan alle guards voldaan is (met \code{CSM\_IF}, de constraint argumenten met \code{CSM\_ARG} en \code{CSM\_LARG} geschreven).
  \item De gevonden combinatie wordt toegevoegd aan de propagation geschiedenis (met \code{CSM\_HISTADD}).
  \item Eventuele removed constraints worden uit de constraint store verwijderd (met \code{CSM\_KILL} en \\ \code{CSM\_KILLSELF}).
  \item De body van de CHR regel wordt uitgevoerd, met de verwijzingen naar lokale variabelen vervangen door \code{CSM\_LOCAL}-macro's en de constraint-argumenten door \code{CSM\_ARG} en \code{CSM\_LARG}.
  \item Als de actieve constraint uit de constraint store verwijderd is, wordt de afhandeling gestopt (\code {CSM\_DEADSELF} en \code{CSM\_END}).
\end{enumerate}

Met deze versie zijn enkele problemen die misschien niet op het eerste zicht duidelijk zijn: \begin{itemize}
  \item Zodra in stap 8 een \code{CSM\_KILL} gebeurd is, kan \code{CSM\_LARG} niet meer gebruikt worden, omdat naar een onbestaande constraint verwezen kan worden of zelfs naar een andere constraint suspension die nu op die plaats staat. Daarom zullen de constraint-argumenten voor de uitvoering van de body opslagen worden in lokale (onwijzigbare) variabelen, met \code{CSM\_IMMLOCAL}. Als er dan verder naar verwezen wordt in de body, wordt \code{CSM\_LOCAL} in plaats van \code{CSM\_LARG} gebruikt.
  \item Het is mogelijk dat een constraint-argument verwijst naar een apart gealloceerd object, dat door middel van een destructor aangegeven is voor vernietiging bij verwijderen van de constraint suspension. Deze destructor kan echter niet aangeroepen worden door \code{CSM\_KILL} in stap 8, omdat code verder in de body misschien nog naar het apart gealloceerd object kan verwijzen. Daarom wordt een \code{CSM\_DESTRUCT} ingevoerd voor elke \code{CSM\_KILL} of \code{CSM\_KILLSELF}, die pas na de body aangeroepen wordt.
  \item Wanneer de actieve constraint nog niet uit de constraint store verwijderd is, maar \'e\'en van de voorgaande partnerconstraints al wel, dan moet de iterator voor die partnerconstraint onmiddellijk overgaan naar het volgende element, om te vermijden dat de body toegepast zou worden voor een op dat moment niet meer bestaande constraint suspension. Daarom wordt na de controle of de actieve constraint nog in de store zit, ook een controle ingevoerd voor alle \code{CSM\_LOOP}s, van buiten naar binnen, door middel van een \code{CSM\_LOOPNEXT} onder voorwaarde van een \code{CSM\_DEAD}. Deze controle is echter niet nodig voor de binnenste lus, aangezien daar sowieso onmiddellijk het volgende element gekozen zal worden.
\end{itemize}

\subsection{Optimalisaties} \label{sec:optim}

Deze eerste versie van het compilatieschema is voor verbetering vatbaar. Een aantal van de hier opgenoemde optimalisaties worden beschreven en verantwoord in \cite{tomsphdthesis}. 

{\bf Dubbels per type}: Het is enkel nodig om te controleren op dubbele constraint suspensions (\code{CSM\_DIFF} en \code{CSM\_DIFFSELF}) tussen suspensions van hetzelfde constraint type in stap 3.

{\bf Propagation geschiedenis}: Men hoeft enkel een propagation geschiedenis bij te houden voor regels die geen removed constraints hebben. Deze laatste kunnen immers sowieso geen twee maal uitgevoerd worden voor dezelfde constraint suspensions. Dit vermijdt soms stappen 4 en 7.

{\bf Destruction}: Indien een destructor aangeroepen moet worden voor een bepaalde constraint suspension, is het niet nodig hiermee te wachten tot na de uitvoering van de gehele body. Dit kan gedaan worden zodra niet meer naar gelijk welke variabele van die constraint verwezen wordt in de regel. De CCHR compiler zal de \code{CSM\_DESTRUCT} macro dan ook plaatsen na het laatste stuk body dat naar een variabele ervan verwijst.

{\bf Late Storage}: Het is wenselijk om het aanmaken van een constraint suspension, en zeker het eigenlijke toevoegen ervan aan de constraint store, zoveel mogelijk uit te stellen. Dit eerste bespaart geheugen en dit tweede kan de snelheid ten goede komen, aangezien er ondertussen minder elementen in de store zijn om over te itereren. Er wordt voor gezorgd dat de suspension aangemaakt is juist voor het zoeken naar partnerconstraints van een propagate-overgang\footnote{Een propagate-overgang komt in onze uitvoer overeen met een occurrence-macro waarbij de actieve constraint geen removed constraint is}, door de \code{CSM\_MAKE} uit stap 1 enkel te plaatsen aan het begin van ``kept'' occurrence macro's. Verder wordt er pas voor gezorgd dat de constraint suspension in de store zit aan het begin van de uitvoering van de body van zo'n propagate-overgang. De \code{CSM\_NEEDSELF} wordt dus geplaatst voor de body van zo'n occurrence.

{\bf Simplification}: Bij simplificatie-overgangen is er zekerheid dat na uitvoering van de body de actieve constraint zich niet meer in de store zal bevinden. Er is dus geen \code{CSM\_DEADSELF} meer nodig in stap 10 om te controleren of een \code{CSM\_END} mag. Dit kan uitgebreid worden tot propagation-overgangen die partnerconstraints verwijderen. Hierbij kan de \code{CSM\_DEAD} conditie rond de \code{CSM\_LOOPNEXT} weggelaten worden. Daarbij komt nog dat na een dergelijke niet-conditionele \code{CSM\_END} of \code{CSM\_LOOPNEXT} geen verdere checks voor de diepere lussen meer nodig zijn en dus volledig weggelaten kunnen worden. Het gebruik van deze expliciete \code{CSM\_LOOPNEXT} macro's komt overeen met wat eerder ``backjumping'' genoemd werd.

{\bf Generation}: Er kan aangetoond worden, dat indien tijdens de uitvoering van de body met een bepaalde actieve constraint suspension, diezelfde constraint suspension gereactiveerd werd, er geen nood meer is om nog verder te proberen regels erop toe te passen. Alle mogelijke regels zijn immers al toegepast tijdens de reactivatie. Dit wordt ge\"implementeerd door in de definitie van \code{CSM\_DEADSELF} op te nemen dat \code{CSM\_DEADSELF} na reactivatie van de actieve constraint ook true is.

\subsection{Join ordering} \label{sec:joinorder}

\Quote{It is in justice that the ordering of society is centered.}{Aristotle (384 BC - 322 BC)}

Een meer ingrijpende optimalisatie die aangebracht kan worden aan voorgaand compilatieschema, is wat men ``join ordering'' noemt, zoals vermeld in \cite{duck:optimizing}. Tot hiertoe werd de volgorde waarin ge\"itereerd wordt over de verschillende partnerconstraints ongedefinieerd gelaten, maar een juiste keuze kan veel versnelling bij de uitvoering mogelijk maken. De ideale volgorde bepalen kan niet altijd, maar het is meestal wel mogelijk een betere keuze te maken dan simpelweg van links naar rechts de head constraints te overlopen.

In het algemeen komt het neer op zoveel mogelijk statements en voorwaardes die gecontroleerd worden voor de uitvoering van de eigenlijke body, zo vroeg mogelijk te doen, dit wil zeggen: binnen zo weinig mogelijk lussen. Een overzicht: \begin{itemize}
  \item Guards (ook impliciete, door HNF convertie)
  \item Controles op dubbele constraints
  \item Propagation geschiedenis controles
  \item Definities van lokale variabelen
  \item Lokale statements in de guard, die tot hiertoe niet vermeld waren.
\end{itemize}
In bovenstaand compilatieschema gebeuren al deze dingen pas zodra over alle partnerconstraints gelopen is, terwijl heel wat mogelijkheden al op voorhand uitgesloten zouden kunnen worden. Daarom wordt geprobeerd zoveel mogelijk van deze dingen reeds tussen de lussen door te controleren. Dit heet ``loop invariant code motion''. Ze kunnen echter afhankelijk zijn van constraints of van contraint-argumenten en lokale variabelen, die zelf ook van eerder gedefinieerde dingen afhankelijk kunnen zijn.

Hiervoor wordt volgend algoritme in de compiler gebruikt: \begin{itemize}
  \item Er wordt ge\"itereerd over alle mogelijke volgordes van iteratie ($O(N!)$ combinaties, met $N$ het aantal partnerconstraints).
  \item Voor elke volgorde wordt geprobeerd elke controle of statement zo vroeg mogelijk te plaatsen, rekening houdende met de eventuele afhankelijkheden van andere variabelen of statements.
  \item Er wordt een ``score'' berekend, die aangeeft hoe snel deze volgorde verwacht wordt te zijn. Deze wordt bepaald door aan alle acties een gewicht toe te kennen en deze te vermenigvuldigen met een factor voor elke lus waarbinnen ze staat.
  \item Uiteindelijk wordt de volgorde met de laagste score gekozen.
\end{itemize}
De heuristieken gebruikt om de gewichten te bepalen zijn redelijk eenvoudig en niet getoetst aan de realiteit. De aldus bekomen volgorde zal in ingewikkelde gevallen vaak niet optimaal zijn, maar experimenteel is wel een duidelijke versnelling gebleken tegenover het na\"ieve geval.

\subsection{Indexen} \label{gencode-index}

\Quote{If you don't find it in the index, look very carefully through the entire catalogue.}{Unknown, Sears, Roebuck, and Co. Consumer's Guide, 1897}

Na al deze verbeteringen blijft het meeste tijd besteed worden aan het opzoeken van de partnerconstraints. In sommige gevallen kunnen de nodige partnerconstraints al bekend zijn, door indexen aan te leggen en te onderhouden. Deze indexen worden dan gebruikt om bij te houden welke constraint suspensions allemaal \'e\'en of meerdere waardes als bepaalde argumenten hebben. Hoe dit ge\"implementeerd is, wordt uitgelegd in sectie~\ref{sec:runtime}.

Om deze indexen te gebruiken in CSM, is het nodig ze eerst in een indexmacro te defini\"eren zoals aangehaald in sectie~\ref{sec:impl}. Daarna is het ook nodig om in plaats van de traditionele \code{CSM\_LOOP} macro enkele andere macro's te gebruiken. Eerst en vooral moet gedeclareerd worden dat een bepaalde variabele als index-iterator gebruikt gaat worden (met \code{CSM\_DEFIDXVAR}). Daarna moeten de op te zoeken waardes voor de verschillende argumenten ingevuld worden met \code{CSM\_SETIDXVAR} en uiteindelijk moet ge\"itereerd worden met \code{CSM\_IDXLOOP} of \code{CSM\_IDXUNILOOP}. Op het verschil tussen beide wordt dadelijk ingegaan.

Deze optimalisatie bleek voor de meeste snelheidswinst te zorgen bij de implementatie. Bij sommige problemen maakt het de uitvoering een grootte-orde sneller door onmiddellijk de juiste constraint te vinden, in plaats van er mogelijk duizenden te moeten doorlopen.

Dit is ge\"implementeerd door bepaalde guards als speciaal te herkennen en aanleiding te laten geven tot indexen. Hoe dit gebeurt wordt uitgelegd in sectie~\ref{sec:matching}.
 
\subsection{Existenti\"ele en universele iteratoren} \label{sec:gencode-iter}

Tijdens het uitvoeren van CCHR code wordt er ge\"itereerd over constraints in verschillende geneste lussen. Middenin die lussen worden er constraints verwijderd, toegevoegd en gereactiveerd. Dit zorgt ervoor dat de toestand van de constraint store en indexen tijdens het itereren op allerlei mogelijke manieren kan veranderen.

Iteratoren die bestand zijn tegen willekeurige wijzigingen en garanderen dat elk element dat uiteindelijk in de store zit ook effectief doorlopen is, zijn heel moeilijk effici\"ent te schrijven. Er wordt dan ook niet ge\"eist dat \code{CSM\_LOOP} en aanverwanten deze functionaliteit aanbieden. Het is echter wel zo, dat constraint suspensions die tijdens het itereren toegevoegd worden aan de store, niet hoeven te worden gecontroleerd als mogelijke partnerconstraints en dus niet noodzakelijk moeten overlopen worden door de iteratoren. Ze zijn immers reeds geactiveerd toen ze zelf toegevoegd werden en ze zouden dus ondertussen reeds alle mogelijke transities met de huidige actieve constraint als partnerconstraint reeds moeten hebben doorgaan. Dit vergemakkelijkt de zaak duidelijk.

Het probleem dat onze iteratoren wijzigingen in de constraint store moeten aankunnen tijdens het itereren blijft echter. Dit blijkt niet altijd nodig te zijn. Indien de simplification-optimalisatie en expliciete backjumping ge\"implementeerd zijn, zal wanneer een CHR regel minstens \'e\'en removed constraint bevat (eventueel de actieve constraint), er na het toepassen van de body van een regel sowieso wordt gesprongen naar de volgende waarde voor de ``meest buitengelegen'' iterator voor een removed constraint of verder. Hieruit volgt dat de lussen die daarbinnen zitten nooit moeten verderlopen eens de body is uitgevoerd.

Om die reden worden voor iteratoren waar het ingewikkeld is, twee verschillende versies aangeboden: \begin{itemize}
\item een versie die slechts volgende mogelijkheden geeft totdat de constraint store gewijzigd kan zijn: de {\em existenti\"ele} iterator.
\item een versie die het algemene geval ook aankan: de {\em universele} iterator.
\end{itemize}

Een universele iterator kan een veel grotere kost hebben om uitgevoerd te worden, wat ook in rekening wordt gebracht bij de kostberekening voor de join ordering.

\subsection{Matching} \label{sec:matching}

Zoals aangehaald is het nodig om bepaalde guards te laten herkennen als effici\"enter te schrijven dan een simpele \code{CSM\_IF}. Het gaat hier om controles die ingebed kunnen worden in een lus. Daarom is een algemene routine geschreven die gegeven de nog te controleren guards op een bepaalde plaats in het uitvoeringsalgoritme, beslist welke soort iterator gebruikt moet worden. De verschillende iteratoren hebben een prioriteit toegekend gekregen en voor elke lus die moet gebeuren wordt de iterator met de hoogst mogelijke prioriteit gekozen.

Er zijn drie iteratoren ge\"implementeerd, van lage naar hoge prioriteit: \begin{enumerate}
\item De simpele \code{CSM\_LOOP} iterator. Deze wordt enkel gekozen als er geen betere iteratoren gevonden kunnen worden. Deze iterator heeft geen impliciete guard.
\item De \code{CSM\_IDXLOOP} iterator die een waarde-index gebruikt voor het itereren. Alle guards die equivalenties voorstellen tussen een variabele die het argument is van eenzelfde constraint occurrence, worden gebruikt om \'e\'en index-iterator te bouwen. Op die manier kunnen een heel aantal guards samen in \'e\'en iterator terechtkomen. Bij de herkenning van dergelijke equivalenties, is de standaard C equivalentie (\code{==}) ondersteund en ook een binaire equivalentie die algemener is (\code{eq(arg1,arg2)}, zie sectie~\ref{sec:rules}).
\item Iteratoren over de elementen van een index in een logische variabele bijgehouden. Dit is slechts gedeeltelijk afgewerkt, maar een voorbeeld kan gevonden worden in sectie~\ref{sec:leq-cchr}.
\end{enumerate}

Bij deze matching komt trouwens het sleutelwoord \code{alt} terug, dat in sectie~\ref{sec:rules} aangehaald werd. Alle argumenten van een \code{alt} worden door het matchalgoritme overlopen, om een zo goed mogelijke match te vinden.

\section{CSM Definities} \label{sec:csmdef}

Bij SWI-Prolog en JCHR kon een duidelijk onderscheid gemaakt worden tussen gegenereerde code en runtime. Bij CCHR is het echter de vraag of de definities van de CSM macro's tot de runtime gerekend kunnen worden. Het is namelijk geen code die tijdens de uitvoering nodig is, maar code die nodig is om de gegenereerde code naar een uitvoerbaar bestand te kunnen omzetten. Daarom zullen de daarin behandelde problemen hier in een aparte sectie besproken worden.

De belangrijkste taak van CSM is de gebruikte datastructuren afschermen van de gegenereerde code, zodat deze beide onafhankelijk gewijzigd kunnen worden. Eerst wordt ingegaan op de gebruikte datastructuren en dan de implementatie ervan zelf besproken.

\subsection{Noodzakelijke datastructuren} \label{sec:datastruct}

{\bf Constraint store} De belangrijkste datastructuur is uiteraard degene voor de constraint store. Het moet een structuur zijn die toelaat heel snel constraints toe te voegen, te verwijderen en erover te itereren. De volgorde volgens dewelke ge\"itereerd wordt is in principe niet van belang, maar het niet-teruggeven van elementen die tijdens het itereren zelf zijn toegevoegd is een pluspunt. Dynamische allocaties tijdens de uitvoering blijven liefst zo veel mogelijk beperkt.

{\bf Propagation geschiedenis} Er moet ook een propagation geschiedenis bijgehouden worden. Deze moet toelaten snel een bepaalde combinatie van constraint suspensions op te zoeken en verwijderen wanneer een van de betrokken constraint suspensions uit de store verwijderd wordt.

{\bf Indexen} Er is een datastructuur nodig om de indexen in bij te houden. Deze moet voor \'e\'en of meerdere argumenten van een bepaalde constraint en voor elke combinatie van waarden voor deze argumenten een lijst kunnen bijhouden van constraint suspensions die deze combinatie van waarden als argumenten heeft.
 
\subsection{De constraint store} \label{sec:constore}

Voor de constraint store wordt gebruikt gemaakt van een structuur van dubbel-gelinkte lijsten. De juiste implementatie wordt uitgewerkt in sectie~\ref{sec:dll}. Hier is het voldoende te weten dat het de mogelijkheid geeft om geheugenblokken van vaste grootte snel te alloceren en vrij te geven. Het kan een op voorhand bepaald aantal disjuncte lijsten bevatten en elk blok kan in maximaal \'e\'en zulke lijst geplaatst worden. Er wordt naar een blok verwezen door middel van een {\em PID} (positie ID), wat herbruikt kan worden nadat een blok vrijgegeven is. Verder krijgt elk blok een uniek {\em ID} dat nooit herbruikt wordt.

Als datablok worden de constraint suspensions gebruikt. Dit is beschreven als een C {\em union}, een structuur die juist \'e\'en van zijn elementen kan bevatten door ze dezelfde geheugenruimte te laten delen, dit in tegenstelling tot een {\em struct} die ze allemaal tegelijk bevat (na elkaar). Als elementen van die union worden de datastructuren voor elk van de verschillende types constraints gebruikt. Dit heeft als nadeel dat er wat plaats verspild wordt als de gegevens voor de verschillende types niet evenveel plaats innemen. Het verschil in grootte tussen de datastructuren voor de verschillende constrainttypes is echter normaal niet groot. Een alternatief is een aparte constraint store gebruiken voor elk van de types, wat dan weer het nadeel heeft van meer allocaties tijdens het uitvoeren.

De lijsten die het dubbel-gelinkte lijst type aanbiedt, bevatten alle constraints van een bepaald type en de \code{CSM\_LOOP} macro gebruikt dan de iterator van de gelinkte lijst om erover te itereren. Het \code{cchr\_id\_t} datatype dat gebruikt wordt voor iteratoren, is dan ook gedefinieerd in het CSM definitiebestand als hetzelfde type dat de dubbel-gelinkte list implementatie gebruikt als {\em PID}. Men kan argumenteren dat de gegenereerde code op die manier toegang krijgt tot een definitie die door CSM afgeschermd zou moeten zijn. De gegenereerde code gebruikt echter het \code{cchr\_id\_t} type zelf niet, krijgt het enkel en geeft het door en moet het verder als ondoorzichtig type beschouwen.

De constraint suspensions zelf bevatten (afhankelijk van het type): \begin{itemize}
  \item De argumenten van de betrokken constraint.
  \item Eventuele propagation geschiedenis (zie sectie~\ref{sec:prophist}).
  \item Een generatienummer. Dit wordt verhoogd elke keer dat een constraint gereactiveerd wordt, om zo de generation optimalisatie te kunnen doorvoeren. Hierbij wordt het generatienummer van de constraint bij activatie bijgehouden en zal de \code{CSM\_DEADSELF} macro ook ``true'' teruggeven indien dat getal ondertussen veranderde.
\end{itemize}

Een \code{CSM\_MAKE} macro zal een nieuw element alloceren in de constraint store, maar het nog niet aan een van de lijsten toevoegen, terwijl een \code{CSM\_NEEDSELF} ervoor zal zorgen dat dat element toegevoegd wordt aan de lijst overeenkomstig met het type constraint van dat element. Indien de constraint zich al in die lijst bevindt, doet deze macro niets. Merk op dat nergens expliciet opgeslagen is van welk constrainttype een bepaald element is: dat volgt impliciet uit de lijst waartoe het behoort. \code{CSM\_KILL} en \code{CSM\_KILLSELF} tenslotte zullen een element zo nodig uit een lijst verwijderen en de plaats vrijgeven voor hergebruik.

Aangezien de datastructuur waarin de constraint suspensions bijgehouden worden de suspensions zelf bevat en geen verwijzingen ernaar, zal een verwijderde constraint gevolgd door de aanmaak van een nieuwe constraint sowieso het vrijgekomen geheugen hergebruiken. Dit samen met de hoge effici\"entie van de gelinkte lijst voor verwijder- en toevoegoperaties, verlaagt de nood aan speciale geheugen-herbruik technieken, zoals voor Prolog beschreven in \cite{jon:memory_reuse}.

\subsection{De propagation geschiedenis} \label{sec:prophist}

\Quote{History repeats itself; that's one of the things that's wrong with history.}{Clarence Darrow (1857 - 1938)}

Om de propagation geschiedenis bij te houden wordt een zelf ge\"implementeerde hashtable gebruikt. Op de implementatie ervan wordt ingegaan in sectie~\ref{sec:hashtable}. Ze vereist dat de gebruiker van de hashtable een datatype aangeeft om in de hashtable te gebruiken, inclusief een manier om te controleren of zulk een datatype een ``gebruikte plaats'' voorstelt.

Voor de propagation geschiedenis wordt dus de \em{ID}s (niet de \em{PID}s) van de betrokken constraint suspensions opgeslagen, voorafgegaan door een $0$ of een $1$, die aangeeft of de plaats in gebruik is. Er zijn twee opties: \begin{enumerate}
  \item Alles opslagen in \'e\'en globale hashtable.
  \item Voor elke regel $R$ waarvoor propagation geschiedenis bijgehouden wordt (geen simplification of simpagation regels dus) \'e\'en van zijn constraint occurrences $O$ van constraint type $C$ kiezen en in de constraint suspensions $S$ van type $C$ de elementen van de propagation geschiedenis opslagen voor regel $R$ die voor occurrence $O$ de suspension $S$ hebben.
\end{enumerate}
Die tweede methode vraagt meer overhead (veel aparte hashtables in plaats van \'e\'en grote), maar zorgt ervoor dat er niet expliciet elementen uit de propagation geschiedenis verwijderd moeten worden. Deze verdwijnen immers automatisch zodra de constraint suspension waarin ze opgeslagen zitten verdwijnt. Er is voor deze tweede optie gekozen.

\subsection{De index} \label{sec:index}

Voor de waarde-indexen, die gebruikt worden met de \code{CSM\_IDXLOOP} en verwante macro's, wordt gebruik gemaakt van de hashtable implementatie die ook voor de propagation geschiedenis gebruikt werd. Ze wordt zelfs twee maal in elkaar gebruikt: eerst een table om de verschillende waardes aan subtables te koppelen en dan in die subtables dan de betrokken constraint suspensions opslagen. Zowel de {\em ID}s als de {\em PID}s worden echter opgeslagen, waarbij de {\em ID}s als unieke sleutel in de hashtable gebruikt worden, terwijl de {\em PID}s als waarden gebruikt worden, om eens een bepaalde constraint gevonden, ze ook snel terug te vinden. Het opslagen van {\em PID}s was bij de propagation geschiedenis niet nodig, aangezien enkel het snel kunnen controleren of een bepaalde (combinatie van) constraint suspension(s) aanwezig was vereist is en het terugvinden van de suspensions zelf niet.

Voor \code{CSM\_IDXLOOP} wordt ge\"itereerd over de verschillende elementen, terwijl er voor \code{CSM\_IDXUNILOOP} eerst een kopie gemaakt wordt van de subtable, waar dan over ge\"itereerd wordt. Dit is nodig, omdat de hashtable implementatie geen wijzigingen tijdens het itereren toelaat. Zie sectie~\ref{sec:hashtable}.

CSM zal automatisch alle indexen onderhouden die met de macro \code{HASHLIST\_\argu{constraint}\_\argu{ariteit}} gedefinieerd zijn, zowel het toevoegen van nieuwe waardes, nieuwe constraint suspensions bij de subtable voor een bestaande waarde toevoegen, het verwijderen van constraint suspensions uit de juiste subtable, en indien er voor een gegeven combinatie van waarden geen overeenkomstige suspensions meer zijn, het verwijderen van de volledige subtable voor die waarden.

\subsection{Debug mode} \label{sec:debug}

Om de gebruiker van CCHR in staat te stellen het precieze uitvoeringsmechanisme van zijn CCHR code te volgen, is een debug mode ge\"introduceerd. Door een optie mee te geven aan de C voorverwerker, kunnen voor bepaalde CSM definities andere versies gebruikt worden die tijdens de uitvoering alle stappen laten zien. Hiervoor is het vereist dat elke constraint definitie een \code{option(fmt,\ldots)} bevat, die informatie geeft hoe de argumenten van een constraint weer te geven. Ook tijdens het schrijven van het programma was dit een grote hulp om fouten te vinden in de gegenereerde code.

\section{Runtime} \label{sec:runtime}

Als ``runtime'' worden alle software-componenten die gemeenschappelijk zijn voor alle CCHR programma's beschouwd, met uitzondering van de CSM definities die reeds behandeld zijn.

Deze componenten behoren tot de runtime: \begin{itemize}
  \item De code voor de dubbel-gelinkte lijsten, die voor de constraint store gebruikt wordt.
  \item De code om met logische variabelen te werken.
  \item De code om de hashtables te onderhouden die voor propagation geschiedenis en indexen gebruikt wordt.
  \item De code voor de hashfunctie voor bovenstaande hashtable.
\end{itemize}

\subsection{Dubbel-gelinkte lijsten} \label{sec:dll}

De gebruikte dubbel-gelinkte lijst structuur, bestaat uit een lijst (array) van elementen van gelijke grootte die in \'e\'en geheel ge(her)alloceerd wordt. Elk element bestaat uit: \begin{itemize}
  \item Een verwijzing naar het volgende element.
  \item Een verwijzing naar het vorige element.
  \item Een uniek ID (dat $0$ is voor niet-gebruikte plaatsen).
  \item De eigenlijke data (die voor de bovenliggende laag beschikbaar is).
\end{itemize}
Door gebruik te maken van de vorige en volgende verwijzingen, worden de verschillende elementen in \'e\'en of meerdere (cyclische) lijsten geplaatst. Deze lijsten kunnen teruggevonden worden door middel van een speciaal markeer-element, dat naar het eerste en het laatste echte element van de lijst verwijst. De elementen op posities $O$ tot en met $N-1$ (met $N$ het aantal lijsten) zijn zulke markeerelementen. De niet-gebruikte plaatsen in de array worden zelf ook in een (enkelvoudig) gelinkte lijst geplaatst, zodat ze snel terug gevonden kunnen worden.

Aangezien het noodzakelijk kan zijn dat het gehele blok van grootte verandert, wat heralloceren en dus mogelijk verplaatsen inhoudt, worden geen echte C pointers als verwijzingen naar de elementen gebruikt. Deze zouden ongeldig worden zodra de hele array verplaatst wordt. In de plaats daarvan wordt de plaats in de array als verwijzing gebruikt. Het is dan ook dit type dat de dubbel-gelinkte lijst code naar buiten toe gebruikt. Het is wat eerder het {\em PID} genoemd werd. 

\subsection{Logische variabelen} \label{sec:logvar}

Om logische variabelen te ondersteunen, onafhankelijk van wat voor gegevens erin opgeslagen worden, is gekozen een macro-definitiebestand te voorzien dat twee macro's definieert: \begin{itemize}
  \item \code{logical\_header(\argu{in},\argu{tag},\argu{out})}: Definieer het datatype \code{\argu{out}}, dat een logische variabele voorstelt die een \code{\argu{in}} kan bevatten en daarbij ook nog \code{\argu{tag}} als metadata heeft.
  \item \code{logical\_code(\argu{in},\argu{tag},\argu{out},\argu{cb})}: Genereer de functies die nodig zijn om met een \code{\argu{out}} datatype te kunnen werken. Deze functies krijgen allen een \code{\argu{out}\_} als prefix en zullen zelf nog enkele andere routines aanroepen die \code{\argu{cb}\_} als prefix hebben.
\end{itemize}

De metadata, opgeslagen in het datatype \code{\argu{tag}}, is bedoeld om informatie te bevatten over de logische variabelen zelf, in plaats van over de waarde die ze voorstellen. Dit zou bijvoorbeeld gebruikt kunnen worden om lijsten bij te houden met welke constraint suspensions gereactiveerd moeten worden indien informatie over de logische variabele verandert. Dit is echter volledig optioneel, aangezien de logische variabelen los van CCHR zelf ge\"implementeerd zijn.

Om het zojuist vermelde voorbeeld te realiseren, worden er enkele ``callback'' routines ondersteund: de gebruiker van de \code{logical\_code} macro moet zelf enkele macro's of functies met een specifieke naam voorzien, die aangeroepen zullen worden door de door \code{logical\_code} gegenereerde code: \begin{itemize}
  \item \code{\argu{cb}\_created(var)}: Aangeroepen zodra een logische variabele \code{var} aangemaakt is. Dit dient om de metadata van deze variabele te initialiseren.
  \item \code{\argu{cb}\_merged(var1,var2)}: Aangeroepen juist voor dat \code{var1} aan \code{var2} gelijkgesteld wordt. Indien de metadata een lijst te reactiveren constraint suspensions zou bevatten, zou deze routine ervoor kunnen zorgen dat de reactivatielijst van \code{var2} bij die van \code{var1} gevoegd wordt.
  \item \code{\argu{cb}\_changed(var)}: Aangeroepen indien er informatie over \code{var} gewijzigd is. Dit is wanneer er een waarde aan toegekend is of wanneer \code{var} aan een andere variabele gelijkgesteld is. Voor het reactivatie-voorbeeld zou deze routine het effectieve reactiveren moeten doen.
  \item \code{\argu{cb}\_destrval(var)}: Aangeroepen wanneer de waarde (type \code{\argu{in}}) van \code{var} vernietigd moet worden.
  \item \code{\argu{cb}\_destrtag(var)}: Aangeroepen wanneer de metadata (type \code{\argu{tag}}) van \code{var} vernietigd moet worden.
\end{itemize}

Voor de implementatie van de code voor logische variabelen, wordt beroep gedaan op het {\em union-find} algoritme, met {\em path compression} en {\em union-by-rank} als optimalisaties toegepast. Het resultaat is dat logische variabelen die aan elkaar gelijk gesteld zijn een boomstructuur gaan vormen, waarbij de top de eventuele bekende waarde bevat. De optimalisaties zorgen ervoor dat de afstand tot de top steeds heel beperkt blijft. Meer informatie over het union-find algoritme, waarvan ook een CHR implementatie bestaat, is te vinden in \cite{tom:unionfind:techreport}.

Het datatype \code{\argu{out}} wordt gedefinieerd als een pointer naar een structuur die volgende informatie kan bevatten: \begin{itemize}
  \item Een waarde, van type \code{\argu{in}}.
  \item Metadata, van type \code{\argu{tag}}.
  \item Een verwijzing naar een andere logische variabele (type \code{\argu{out}}).
  \item Een aanduiding of de structuur al dan niet een waarde bevat.
  \item Een {\em rank}, zijnde het niveau in de boomstructuur.
  \item Een {\em reference count}, om te weten wanneer de structuur vrijgegeven mag worden.
\end{itemize}
Al deze elementen zijn verspreid over een structuur van C structs en unions, zodat geen twee velden die nooit tegelijk nodig zijn samen plaats innemen.

\subsection{De hashtable} \label{sec:hashtable}

Een hashtable is in het algemeen een datastructuur die bedoeld is om elementen heel snel in op te slagen en op te zoeken. Het maakt gebruik een ``hashfunctie'' die de op te slagen elementen afbeeldt op een natuurlijk getal binnen een bepaald bereik. Elementen worden dan opgeslagen op een positie die afhankelijk is van het resultaat van deze hashfunctie. Deze hashfunctie is liefst zo grillig mogelijk, om patronen in de invoer geen patronen in de uitvoer te laten veroorzaken. Op deze hashfunctie wordt in sectie~\ref{sec:hashfunc} op ingegaan.

Het grootste probleem met hashtables is het probleem van ``collisions''. Dat zijn verschillende elementen die op dezelfde plaats zouden terechtkomen in de tabel. De kans dat zulke collisions optreden, kan bepaald worden met wat het ``verjaardagsprobleem'' genoemd wordt --- gelijkaardig aan de kans bepalen dat twee mensen in een groep dezelfde verjaardag hebben. Vereenvoudigd kan gesteld worden dat een eerste collision ongeveer optreedt wanneer het aantal elementen $N$ gelijk is aan $\sqrt{D}$, met $D$ het aantal plaatsen in de tabel.

Hieruit volgt dat het onmogelijk is de tabel gevuld te houden eens er een redelijk aantal elementen in opgeslagen moeten worden. Er zijn verschillende traditionele oplossingen voor dit probleem: \begin{enumerate}
\item De tabel wordt vergroot zodra een collision optreedt.
\item Er wordt toegestaan dat \'e\'en tabelpositie meerdere elementen bevat.
\item Indien een plaats bezet is, wordt het gegeven element \'e\'en plaats verder geplaatst.
\end{enumerate}

Elk van deze methodes kent zijn nadelen. Een overzicht: \begin{enumerate}
\item Dit leidt veel te snel tot teveel geheugengebruik, wat meestal onaanvaardbaar is.
\item Indien een tabelpositie naar verscheidene elementen kan refereren, is er een aparte datastructuur nodig die deze elementen bevat. Deze zal normaal gezien per verschillende waarde een geheugenallocatie vragen. 
\item Hierbij treedt een soort fragmentatie van de geheugenruimte op. Stel dat 2 elementen A en B een hashwaarde hebben die hen op plaats $N$ afbeeldt. A wordt op plaats $N$ gezet en B op plaats $N+1$. Stel nu dat A verwijderd wordt: plaats $N$ mag niet leeggemaakt worden, aangezien het opzoeken van B zou beginnen op plaats $N$, die leeg is, en onmiddellijk falen. Daarom moet plaats $N$ dan als ``ooit in gebruik geweest'' gemarkeerd worden en niet echt als vrij. Als bij het opzoeken van B deze speciale waarde dan tegengekomen wordt, wordt verdergezocht tot ofwel B ofwel een echte lege plaats tegengekomen wordt.
\end{enumerate}

Daarom is gekozen om een andere minder bekende techniek te gebruiken: {\em Cuckoo Hashing}. Hierbij worden twee verschillende tabellen (A en B) gebruikt, waarin twee onafhankelijke hashfuncties gebruikt worden. Elk element dat toegevoegd wordt, komt op zijn correcte plaats in tabel A terecht en indien die plaats reeds benomen is, wordt het element dat daar stond naar zijn plaats in tabel B verplaatst. Indien daar reeds iets stond, wordt dat teruggeplaatst naar zijn plaats in tabel A, enzovoort. Deze techniek en enkele analyses erop worden vermeld in \cite{cuckoo}.

In het kader van deze thesis is dat algoritme ge\"implementeerd (alweer) als een macro defintiebestand. Een datatype als hastable definieren gebeurt mits: \\
\code{ht\_cuckoo\_code(\argu{hash\_t},\argu{entry\_t},\argu{hash1},\argu{hash2},\argu{eq},\argu{defined},\argu{init},\argu{unset})}. Hierbij wordt het type \argu{hash\_t} gedefinieerd als een hashtable die elementen van het type \argu{entry\_t} kan bevatten. \argu{hash1} en \argu{hash2} zijn de namen van de 2 te gebruiken hashfuncties. De functie \argu{eq} moet controleren of twee elementen aan elkaar gelijk zijn, \argu{defined} of een element een ``vrije'' plaats voorstelt en \argu{init} en \argu{unset} dienen om een element te initialiseren als ongebruikt en om het terug vrij te geven.

Om te vermijden dat er oneindige lussen ontstaan bij het heen en weer verplaatsen van elementen in de hashtable, wordt zoals voorgesteld in het artikel een limiet opgelegd op het aantal iteraties dat er mogen gebeuren voor de tabelgrootte verdubbeld wordt. Als de tabel meer dan $5/12$ gevuld is, wordt ze ook automatisch verdubbeld van grootte.

\subsection{De hashfunctie} \label{sec:hashfunc}

Met de gebruikte hashtable is het vrij essentieel dat een goede hashfunctie gebruikt wordt. De invoer (zijnde de elementen die geplaatst moeten worden in de tabel) bevat vaak patronen, zoals opeenvolgende getallen. Indien dit patroon zou resulteren in een verhoogde kans op collisions, zou de kwaliteit van het hashtable algoritme al snel achteruit gaan.

Voor de hasfunctie is gekozen voor ``lookup3'', een publiek-domein algoritme. Zie \cite{hashing} voor meer informatie.

\section{Geschreven code} \label{sec:correctheid}

\subsection{Standaarden} \label{sec:standards}

Alle code, zowel de compiler als de gegenereerde code, is C code of iets dat ernaar omgezet wordt. De programmeertaal C bestaat echter in vele varianten en er zijne vele standaarden voor gedefinieerd. Wat betreft de C compiler is steeds gebruik gemaakt van de {\em GNU Compiler Collection} (GCC). De CCHR compiler broncode heeft geen externe afhankelijkheden van andere projecten of bibliotheken en is volledig conform aan de ``C99'' standaard (ISO 9899:1999). Merk op dat GCC zelf nog niet volledig C99 ondersteunt, maar de broncode gebruikt ook geen functionaliteit die niet in GCC 3.3 aanwezig is. De gegenereerde code, of beter gezegd, de huidige CSM definities, maken gebruik van 1 mogelijkheid die niet tot de C99 standaard behoort en slechts vanaf GCC 4 beschikbaar is: ``local labels''. Deze worden gebruikt om op een elegante manier uit geneste lussen te springen.

\subsection{Geheugenlekken} \label{sec:memleaks}

\Quote{It's no use carrying an umbrella if your shoes are leaking.}{Irish proverb}

In beide gevallen wordt vaak gebruik gemaakt van het dynamisch geheugen dat deze taal aanbiedt, met behulp van de systeemfuncties \code{malloc()}, \code{free()} en \code{realloc()}. Het probleem met gebruik hiervan is dat de programmeur volledig zelf verantwoordelijk wordt voor het geheugenbeheer. Er moet voor gezorgd worden dat elke byte gealloceerd geheugen ook effectief vrijgegeven wordt en dat er nooit naar niet-gealloceerd of reeds-vrijgegeven geheugen verwezen wordt. Om deze fouten te kunnen opsporen is gebruik gemaakt van de geheugendebuggers {\em valgrind} en {\em Electric Fence} en van de {\em boundschecking} patch voor GCC. Zowel de compiler zelf als de gegenereerde code zijn vaak met deze tools gecontroleerd en in de uiteindelijke versie zijn dan ook geen ``geheugenlekken'' of gebruik van niet-gealloceerd geheugen meer gevonden.

Uiteraard blijft de gebruiker van de CCHR compiler wel verantwoordelijk om zelf geen geheugenlekken te veroorzaken, bv. door C code die in de body van een CHR regel staat. Het is eventueel mogelijk om van niet-standaard geheugenbeheer bibliotheken gebruik te maken, zoals de Boehm collector (\cite{boehmgc}) gebruikt in libgc (\cite{libgc}), die de programmeur de verantwoordelijkheid alle zelf gealloceerd geheugen vrij te geven ontnemen.

\subsection{Cijfermateriaal} \label{sec:cijfer}

Een overzicht van de geschreven code: \begin{itemize}
\item De geschreven compiler bestaat uit 6 verschillende C-bronbestanden, 8 C-headerbestanden, een lexer in Flex en een parser in Bison, samen ongeveer 3700 lijnen code.
\item Daarbij komen nog 5 C-headerbestanden die de CSM definities en de rest van de runtime bevatten, samen ongeveer 1300 lijnen code.
\item Er zijn 14 CHR voorbeeldprogramma's vertaald naar CCHR, die echter niet allemaal voor benchmarks gebruikt zijn. Samen zijn ze goed voor 700 lijnen code.
\item Voor benchmarks (zie hoofdstuk~\ref{chap:bench}) zijn nog 7 voorbeeldprogramma's zo effici\"ent mogelijk in C geschreven, samen 350 lijnen.
\item Daarbuiten zijn er nog ongeveer 500 lijnen code geschreven in Makefiles en scripts voor het uitvoeren van de benchmarks en het genereren van de grafieken ervan.
\item Alles bij mekaar meer dan 6500 lijnen, de gegenereerde parser en lexer en de code van het lookup3 hash-algoritme niet meegerekend.
\end{itemize}

